{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6edf10",
   "metadata": {},
   "source": [
    "# Faculty Analysis\n",
    "\n",
    "Mostly this notebook is pre-processing and tidying the data for the R analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3699d9",
   "metadata": {},
   "source": [
    "## Loading the data from mturk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44cfa33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from itertools import chain\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f265bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"faculty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0109acb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>assignment_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FACULTY_20210816_prod</td>\n",
       "      <td>d489de33-e5b1-4829-b6c2-a0817d6a3b51</td>\n",
       "      <td>35010157605115141260511511080192024</td>\n",
       "      <td>experiment</td>\n",
       "      <td>PAPER_REVIEW_PILOT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FACULTY_20210816_prod</td>\n",
       "      <td>d489de33-e5b1-4829-b6c2-a0817d6a3b51</td>\n",
       "      <td>35010157605115141260511511080192024</td>\n",
       "      <td>stage</td>\n",
       "      <td>INITIAL_PAGE_LOAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FACULTY_20210816_prod</td>\n",
       "      <td>d489de33-e5b1-4829-b6c2-a0817d6a3b51</td>\n",
       "      <td>35010157605115141260511511080192024</td>\n",
       "      <td>variant</td>\n",
       "      <td>FACULTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FACULTY_20210816_prod</td>\n",
       "      <td>d489de33-e5b1-4829-b6c2-a0817d6a3b51</td>\n",
       "      <td>35010157605115141260511511080192024</td>\n",
       "      <td>condition</td>\n",
       "      <td>SE_NO_FEEDBACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FACULTY_20210816_prod</td>\n",
       "      <td>d489de33-e5b1-4829-b6c2-a0817d6a3b51</td>\n",
       "      <td>35010157605115141260511511080192024</td>\n",
       "      <td>currentTime</td>\n",
       "      <td>1629123522396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  hit_id                         assignment_id  \\\n",
       "0  FACULTY_20210816_prod  d489de33-e5b1-4829-b6c2-a0817d6a3b51   \n",
       "1  FACULTY_20210816_prod  d489de33-e5b1-4829-b6c2-a0817d6a3b51   \n",
       "2  FACULTY_20210816_prod  d489de33-e5b1-4829-b6c2-a0817d6a3b51   \n",
       "3  FACULTY_20210816_prod  d489de33-e5b1-4829-b6c2-a0817d6a3b51   \n",
       "4  FACULTY_20210816_prod  d489de33-e5b1-4829-b6c2-a0817d6a3b51   \n",
       "\n",
       "                             worker_id     variable                value  \n",
       "0  35010157605115141260511511080192024   experiment  PAPER_REVIEW_PILOT2  \n",
       "1  35010157605115141260511511080192024        stage    INITIAL_PAGE_LOAD  \n",
       "2  35010157605115141260511511080192024      variant              FACULTY  \n",
       "3  35010157605115141260511511080192024    condition       SE_NO_FEEDBACK  \n",
       "4  35010157605115141260511511080192024  currentTime        1629123522396  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"../raw-data/{experiment}.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b079c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, there are 566 unique assignmentIds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall, there are {df.assignment_id.nunique()} unique assignmentIds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7661044b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199    288\n",
       "24      77\n",
       "12      46\n",
       "37      42\n",
       "51      33\n",
       "67      29\n",
       "86      20\n",
       "162      7\n",
       "105      6\n",
       "143      6\n",
       "180      6\n",
       "124      4\n",
       "98       1\n",
       "185      1\n",
       "Name: assignment_id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.assignment_id.value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd081eb",
   "metadata": {},
   "source": [
    "# Analysis of Part I\n",
    "\n",
    "Since we have more data for Part I of the experiment, let's look at that first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de1c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_markers = df[df.variable == 'experiment'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30284d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stages = []\n",
    "\n",
    "for stage_start, stage_end in zip(stage_markers, np.concatenate([stage_markers[1:], [len(df)]])):\n",
    "    df_stage = df.iloc[stage_start:stage_end]\n",
    "    df_stage_pivoted = df_stage.pivot(index='assignment_id', columns='variable', values='value')\n",
    "    \n",
    "    df_stages.append(df_stage_pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc27679c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>assignmentId</th>\n",
       "      <th>condition</th>\n",
       "      <th>currentTime</th>\n",
       "      <th>experiment</th>\n",
       "      <th>hitId</th>\n",
       "      <th>id</th>\n",
       "      <th>stage</th>\n",
       "      <th>startTime</th>\n",
       "      <th>study_id</th>\n",
       "      <th>turkSubmitTo</th>\n",
       "      <th>variant</th>\n",
       "      <th>workerId</th>\n",
       "      <th>paperA_editorialResponse</th>\n",
       "      <th>paperA_superiorityEstimate</th>\n",
       "      <th>paperA_whatYouSaw</th>\n",
       "      <th>paperA_whatYouSaw2</th>\n",
       "      <th>guess</th>\n",
       "      <th>scenario</th>\n",
       "      <th>trial</th>\n",
       "      <th>background</th>\n",
       "      <th>feedback</th>\n",
       "      <th>q_appeal</th>\n",
       "      <th>q_sample_size</th>\n",
       "      <th>q_overall</th>\n",
       "      <th>mu1</th>\n",
       "      <th>mu2</th>\n",
       "      <th>variance1</th>\n",
       "      <th>variance2</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>probOfSuperiority</th>\n",
       "      <th>departmentField</th>\n",
       "      <th>isTenureTrackFaculty</th>\n",
       "      <th>comfortWithStats</th>\n",
       "      <th>comfortWithData</th>\n",
       "      <th>taughtStats</th>\n",
       "      <th>papersReviewed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assignment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d489de33-e5b1-4829-b6c2-a0817d6a3b51</th>\n",
       "      <td>d489de33-e5b1-4829-b6c2-a0817d6a3b51</td>\n",
       "      <td>SE_NO_FEEDBACK</td>\n",
       "      <td>1629123522396</td>\n",
       "      <td>PAPER_REVIEW_PILOT2</td>\n",
       "      <td>FACULTY_20210816_prod</td>\n",
       "      <td>ff61b793-c49d-4e34-8265-ee35a4bdca73</td>\n",
       "      <td>INITIAL_PAGE_LOAD</td>\n",
       "      <td>1629123522355</td>\n",
       "      <td>paper-review-pilot-2</td>\n",
       "      <td>None</td>\n",
       "      <td>FACULTY</td>\n",
       "      <td>35010157605115141260511511080192024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e6bb3497-3963-4c0d-848d-9be80c22cfe8</th>\n",
       "      <td>e6bb3497-3963-4c0d-848d-9be80c22cfe8</td>\n",
       "      <td>SE_POINTS_NO_FEEDBACK</td>\n",
       "      <td>1629123537366</td>\n",
       "      <td>PAPER_REVIEW_PILOT2</td>\n",
       "      <td>FACULTY_20210816_prod</td>\n",
       "      <td>96a3ac87-d7bb-446d-836f-1270f10874f3</td>\n",
       "      <td>INITIAL_PAGE_LOAD</td>\n",
       "      <td>1629123537317</td>\n",
       "      <td>paper-review-pilot-2</td>\n",
       "      <td>None</td>\n",
       "      <td>FACULTY</td>\n",
       "      <td>35010157605115141260511511080192024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2bcda2d4-9071-4be3-a835-40d2a08d0fc1</th>\n",
       "      <td>2bcda2d4-9071-4be3-a835-40d2a08d0fc1</td>\n",
       "      <td>SE_POINTS_NO_FEEDBACK</td>\n",
       "      <td>1629127672152</td>\n",
       "      <td>PAPER_REVIEW_PILOT2</td>\n",
       "      <td>FACULTY_20210816_prod</td>\n",
       "      <td>a4402841-1597-4357-a06e-721a3d040e2a</td>\n",
       "      <td>INITIAL_PAGE_LOAD</td>\n",
       "      <td>1629127672031</td>\n",
       "      <td>paper-review-pilot-2</td>\n",
       "      <td>None</td>\n",
       "      <td>FACULTY</td>\n",
       "      <td>4501006464537369204515131537363864153624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2bcda2d4-9071-4be3-a835-40d2a08d0fc1</th>\n",
       "      <td>2bcda2d4-9071-4be3-a835-40d2a08d0fc1</td>\n",
       "      <td>SE_POINTS_NO_FEEDBACK</td>\n",
       "      <td>1629127693898</td>\n",
       "      <td>PAPER_REVIEW_PILOT2</td>\n",
       "      <td>FACULTY_20210816_prod</td>\n",
       "      <td>efbeb6e0-eca6-412d-8e59-636951b7e692</td>\n",
       "      <td>PAPER_A_PREFACE</td>\n",
       "      <td>1629127672031</td>\n",
       "      <td>paper-review-pilot-2</td>\n",
       "      <td>None</td>\n",
       "      <td>FACULTY</td>\n",
       "      <td>4501006464537369204515131537363864153624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2bcda2d4-9071-4be3-a835-40d2a08d0fc1</th>\n",
       "      <td>2bcda2d4-9071-4be3-a835-40d2a08d0fc1</td>\n",
       "      <td>SE_POINTS_NO_FEEDBACK</td>\n",
       "      <td>1629127796257</td>\n",
       "      <td>PAPER_REVIEW_PILOT2</td>\n",
       "      <td>FACULTY_20210816_prod</td>\n",
       "      <td>27d7c08c-8034-48b8-a211-425ee5bc8192</td>\n",
       "      <td>PAPER_A_REVIEW</td>\n",
       "      <td>1629127672031</td>\n",
       "      <td>paper-review-pilot-2</td>\n",
       "      <td>None</td>\n",
       "      <td>FACULTY</td>\n",
       "      <td>4501006464537369204515131537363864153624</td>\n",
       "      <td>{'q_appeal': '4', 'q_sample_size': '5', 'q_ove...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "variable                                                      assignmentId  \\\n",
       "assignment_id                                                                \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51  d489de33-e5b1-4829-b6c2-a0817d6a3b51   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8  e6bb3497-3963-4c0d-848d-9be80c22cfe8   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  2bcda2d4-9071-4be3-a835-40d2a08d0fc1   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  2bcda2d4-9071-4be3-a835-40d2a08d0fc1   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  2bcda2d4-9071-4be3-a835-40d2a08d0fc1   \n",
       "\n",
       "variable                                          condition    currentTime  \\\n",
       "assignment_id                                                                \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51         SE_NO_FEEDBACK  1629123522396   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8  SE_POINTS_NO_FEEDBACK  1629123537366   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  SE_POINTS_NO_FEEDBACK  1629127672152   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  SE_POINTS_NO_FEEDBACK  1629127693898   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  SE_POINTS_NO_FEEDBACK  1629127796257   \n",
       "\n",
       "variable                                       experiment  \\\n",
       "assignment_id                                               \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51  PAPER_REVIEW_PILOT2   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8  PAPER_REVIEW_PILOT2   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  PAPER_REVIEW_PILOT2   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  PAPER_REVIEW_PILOT2   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  PAPER_REVIEW_PILOT2   \n",
       "\n",
       "variable                                              hitId  \\\n",
       "assignment_id                                                 \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51  FACULTY_20210816_prod   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8  FACULTY_20210816_prod   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  FACULTY_20210816_prod   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  FACULTY_20210816_prod   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  FACULTY_20210816_prod   \n",
       "\n",
       "variable                                                                id  \\\n",
       "assignment_id                                                                \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51  ff61b793-c49d-4e34-8265-ee35a4bdca73   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8  96a3ac87-d7bb-446d-836f-1270f10874f3   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  a4402841-1597-4357-a06e-721a3d040e2a   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  efbeb6e0-eca6-412d-8e59-636951b7e692   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  27d7c08c-8034-48b8-a211-425ee5bc8192   \n",
       "\n",
       "variable                                          stage      startTime  \\\n",
       "assignment_id                                                            \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51  INITIAL_PAGE_LOAD  1629123522355   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8  INITIAL_PAGE_LOAD  1629123537317   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  INITIAL_PAGE_LOAD  1629127672031   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1    PAPER_A_PREFACE  1629127672031   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1     PAPER_A_REVIEW  1629127672031   \n",
       "\n",
       "variable                                          study_id turkSubmitTo  \\\n",
       "assignment_id                                                             \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51  paper-review-pilot-2         None   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8  paper-review-pilot-2         None   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  paper-review-pilot-2         None   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  paper-review-pilot-2         None   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  paper-review-pilot-2         None   \n",
       "\n",
       "variable                              variant  \\\n",
       "assignment_id                                   \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51  FACULTY   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8  FACULTY   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  FACULTY   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  FACULTY   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  FACULTY   \n",
       "\n",
       "variable                                                              workerId  \\\n",
       "assignment_id                                                                    \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51       35010157605115141260511511080192024   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8       35010157605115141260511511080192024   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  4501006464537369204515131537363864153624   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  4501006464537369204515131537363864153624   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  4501006464537369204515131537363864153624   \n",
       "\n",
       "variable                                                       paperA_editorialResponse  \\\n",
       "assignment_id                                                                             \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51                                                NaN   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8                                                NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1                                                NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1                                                NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1  {'q_appeal': '4', 'q_sample_size': '5', 'q_ove...   \n",
       "\n",
       "variable                             paperA_superiorityEstimate  \\\n",
       "assignment_id                                                     \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51                        NaN   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8                        NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1                        NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1                        NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1                        NaN   \n",
       "\n",
       "variable                             paperA_whatYouSaw paperA_whatYouSaw2  \\\n",
       "assignment_id                                                               \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51               NaN                NaN   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8               NaN                NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1               NaN                NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1               NaN                NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1               NaN                NaN   \n",
       "\n",
       "variable                              guess scenario trial background  \\\n",
       "assignment_id                                                           \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51    NaN      NaN   NaN        NaN   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8    NaN      NaN   NaN        NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1    NaN      NaN   NaN        NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1    NaN      NaN   NaN        NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1    NaN      NaN   NaN        NaN   \n",
       "\n",
       "variable                             feedback q_appeal q_sample_size  \\\n",
       "assignment_id                                                          \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51      NaN      NaN           NaN   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8      NaN      NaN           NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1      NaN      NaN           NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1      NaN      NaN           NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1      NaN        4             5   \n",
       "\n",
       "variable                             q_overall  mu1  mu2  variance1  \\\n",
       "assignment_id                                                         \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51       NaN  NaN  NaN        NaN   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8       NaN  NaN  NaN        NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1       NaN  NaN  NaN        NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1       NaN  NaN  NaN        NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1         2  NaN  NaN        NaN   \n",
       "\n",
       "variable                              variance2  n1  n2  probOfSuperiority  \\\n",
       "assignment_id                                                                \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51        NaN NaN NaN                NaN   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8        NaN NaN NaN                NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1        NaN NaN NaN                NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1        NaN NaN NaN                NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1        NaN NaN NaN                NaN   \n",
       "\n",
       "variable                             departmentField isTenureTrackFaculty  \\\n",
       "assignment_id                                                               \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51             NaN                  NaN   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8             NaN                  NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1             NaN                  NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1             NaN                  NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1             NaN                  NaN   \n",
       "\n",
       "variable                             comfortWithStats comfortWithData  \\\n",
       "assignment_id                                                           \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51              NaN             NaN   \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8              NaN             NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1              NaN             NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1              NaN             NaN   \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1              NaN             NaN   \n",
       "\n",
       "variable                             taughtStats papersReviewed  \n",
       "assignment_id                                                    \n",
       "d489de33-e5b1-4829-b6c2-a0817d6a3b51         NaN            NaN  \n",
       "e6bb3497-3963-4c0d-848d-9be80c22cfe8         NaN            NaN  \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1         NaN            NaN  \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1         NaN            NaN  \n",
       "2bcda2d4-9071-4be3-a835-40d2a08d0fc1         NaN            NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def literal_eval_if_present(val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    \n",
    "    return literal_eval(val)\n",
    "\n",
    "\n",
    "def get_if_present(col, val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    \n",
    "    return val[col]\n",
    "\n",
    "\n",
    "def in_get_if_present(col, inner, val):\n",
    "    gotten = get_if_present(col, val)\n",
    "    \n",
    "    try:\n",
    "        return inner in gotten\n",
    "    except TypeError:\n",
    "        return gotten\n",
    "    \n",
    "\n",
    "def int_if_present(val):\n",
    "    if pd.isnull(val):\n",
    "        return val\n",
    "    \n",
    "    return int(val)\n",
    "\n",
    "df_by_stage = pd.concat(df_stages)\n",
    "df_by_stage['paperA_editorialResponse'] = df_by_stage['paperA_editorialResponse'].apply(literal_eval_if_present)\n",
    "df_by_stage['scenario'] = df_by_stage['scenario'].apply(literal_eval_if_present)\n",
    "df_by_stage['background'] = df_by_stage['background'].apply(literal_eval_if_present)\n",
    "df_by_stage['guess'] = df_by_stage['guess'].apply(int_if_present)\n",
    "df_by_stage['currentTime'] = df_by_stage['currentTime'].apply(int_if_present)\n",
    "df_by_stage['startTime'] = df_by_stage['startTime'].apply(int_if_present)\n",
    "\n",
    "{'departmentField': 'statistics',\n",
    " 'isTenureTrackFaculty': 'no',\n",
    " 'comfortWithStats': '5',\n",
    " 'comfortWithData': '5',\n",
    " 'taughtStats': 'Yes',\n",
    " 'papersReviewed': '50-100'}\n",
    "\n",
    "editorialQs = ['q_appeal', 'q_sample_size', 'q_overall']\n",
    "scenarioVars = ['mu1', 'mu2', 'variance1', 'variance2', 'n1', 'n2', 'probOfSuperiority']\n",
    "statsVars = ['departmentField', 'isTenureTrackFaculty', 'comfortWithStats', 'comfortWithData', 'taughtStats', 'papersReviewed']\n",
    "\n",
    "for q in editorialQs:\n",
    "    df_by_stage[q] = df_by_stage.paperA_editorialResponse.apply(lambda x: get_if_present(q, x))\n",
    "\n",
    "for v in scenarioVars:\n",
    "    df_by_stage[v] = df_by_stage.scenario.apply(lambda x: get_if_present(v, x))\n",
    "\n",
    "for v in statsVars:\n",
    "    df_by_stage[v] = df_by_stage.background.apply(lambda x: get_if_present(v, x))\n",
    "\n",
    "df_by_stage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753acd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering on date:  4460\n",
      "After removing responses after August 26th, 2021:  4460\n"
     ]
    }
   ],
   "source": [
    "# Filter faculty who replied after Thursday August 26th\n",
    "\n",
    "print(\"Before filtering on date: \", len(df_by_stage))\n",
    "df_by_stage = df_by_stage[(df_by_stage['startTime'] / 1000).apply(lambda x: datetime.fromtimestamp(x).date()) <= date(2021, 8, 26)]\n",
    "print(\"After removing responses after August 26th, 2021: \", len(df_by_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671a2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials = df_by_stage[~df_by_stage.trial.isnull()]\n",
    "\n",
    "# only keep people who finished all 5 trials\n",
    "df_trials = df_trials[\n",
    "    df_trials.groupby('assignmentId').trial.transform('count') == 5\n",
    "]\n",
    "\n",
    "df_trials['psup'] = (df_trials.probOfSuperiority*100).astype(int)\n",
    "df_trials['signed_error'] = df_trials.guess - df_trials.psup\n",
    "df_trials['unsigned_error'] = np.abs(df_trials.guess - df_trials.psup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d286b9b2",
   "metadata": {},
   "source": [
    "# Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ddf5c00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I found it more challenging than expected since my discipline deals w/ much larger N studies in which scatterplots or graphs showing individual data points are rarely informative. Good luck w/ your project. ',\n",
       "       'Interesting exercise!',\n",
       "       \"It's profoundly stoopid to estimate these probabilities; they are not what is at stake in hypothesis testing.  If one wants to know those probabilities, one can write code to calculate them from normal distribution tables, which is why is entered the lowest estimate possible for all of them.  Stoopid questions indeed.\",\n",
       "       'Cool study and I like the \"reward\" for participation!',\n",
       "       \"Ok, I've reviewed lots of papers, but never an experiment (or even group differences with small Ns).  So these were all wild guesses.\",\n",
       "       \"It took me a few goes to recognize your jargon. What you were calling standard error, I *think* was what I know as the standard error of the mean which is roughly the sd/sqrt(N). After I caught on that you didn't mean standard deviation, I would have liked to go back to look at the first question and its wording, and probably revise my answer. \",\n",
       "       'In my field of physics, all data points are plotted with +- 1 standard deviation on them.  Also the only thing we call the \"error\" on a set of data points is in fact the 1 sigma standard deviation.  On the very first page you said in the text the points were 6.something with standard deviation of 0.5 or so.  This was for both samples.  This was not how the error bars were presented in the plot.  The error bars in the plot didn\\'t even look like they were 1/2 of a standard deviation per point.  Thus if I were reviewing this paper for real I would have rejected it b/c the conclusion is very wrong (both points of 6.something were within 1 standard deviation of each other - there was no strong indication video games changed behavior) and the plot being incorrectly presented.  I don\\'t use p scores and actually don\\'t know what they mean.  We never use those in my field.  I thought they were only used in the medical field.  Based on how the error bars drawn on the first page did not match what I expect in my field I was totally baffled by what they represented in the following 5 cases and had no idea how to answer correctly.  It\\'s too bad this is anonymous b/c I\\'d appreciate more clarification on how things are done in your field and why we are not using data points and errors the same way to convey information.  ',\n",
       "       'This was a difficult and tricky test with the choices and guessing we had to do! The \"P\" values are for the probability of a type I error for the null hypothesis of no difference between the two groups. To get the probabilities that you were asking us to guess depended on the overlap of the standard errors for different probability curves (e.g., 1.96 s.e. = two tailed 95% probability range for each group and then try to guess on the visual overlaps of the two groups at that number of s.e.! I always tried to get students to do visual estimates of various aspects during data analyses so they could have a sense of their analyses outcomes were in the right ball park. But this test was a bit more sophisticated than usual for visual estimation. I\\'m not particularly confident in my guesses, i.e., I suspect that the guesses themselves would have very wide confidence intervals even for respondents who know what they\\'re doing! (Although note: Depending partly on the sample size of respondents that you end up with (I\\'m guessing a large number*), because of the Central Limit Theorem, I would expect the estimated means of the guesses to be fairly accurate.) \\n____________\\n* Also note: The number of respondents might be a crap shoot, as \"smart\" internet users these days are not likely to respond to unsolicited emails due to the risk of malware. I was myself was very leery of responding and gave it careful and long consideration to do so. I only responded because of the @microsoft.com domain and what appeared to be too straight forward and yet sophisticated of a study to be worth a hacker\\'s time to develop and send out. But, ... I\\'m becoming leerier and leerier every day as hackers get more and more sophisticated themselves and go after specialized groups, including researchers with advanced degrees. (I WAS a tenture track professor but am currently retired, hence, my answer to that early question.) Anyway, it\\'s an arms race and I (and others) are trying to stay ahead of the game. ... That likely is biasing and limiting this study, for what it\\'s worth (and if I was reviewing the results!).',\n",
       "       'I am reasonably comfortable with interpreting inferential statistics but I have not generally used plots of errors rather than probability estimates. My research for the last decade or so has been theoretical and historical but I have done surveys in the past but always with coauthors who had more statistical training than i have had. I do lots of reviewing but my comments are usually directed to research questions, relevant literature and basic consistency regarding quantitative analyses but I let editors know to allow others to address statistical issues. ',\n",
       "       \"The questions (not the study) got me to think about the relative sizes of random fluctuations and the 'effect' measured, but it focussed my attention on the fact that I had no clean criterion for comparing the sizes.  In my particular field (theoretical electronic structure) I have rarely needed to assess statistical errors, because most errors are systematic.\",\n",
       "       'I took this quiz after drinking two glasses of wine and quickly decided not to perform any calculations to determine the SD of outcomes in each group.',\n",
       "       'You had some inconsistencies of labeling scaling in the graphs.  Also, I had to try and guess mean and SE from the graphs in order to get data for simulation.  Were that intended?  I understood you wished to reveal misunderstandings of SE vs. SD, and confusions of sample vs. population, but you may have unintentionally confused it with other issues.. Also, there were some ambiguities and misuse of language.  Also, in some cases, where you did not give information about the distributions, only mean and sd, your questions were technically unanswerable, so the correct answer (in some cases) would be \"cannot be determined from the info. available.)  Finally, it\\'s a misnomer to say that sample data are normally distributed.  That\\'s a statement about a population.  You could say \"sample is distributed as though it came from a normal population.\"  ',\n",
       "       'i am tired and this test was too long after a long day.',\n",
       "       'The text and the figure on the first page did not agree.  The standard deviation in the text was 0.5 and the figure the sandard deviation was 0.05',\n",
       "       'I completed this when I was overly tired',\n",
       "       'I think the value of this study is immediately important as I teach social policy and my undergraduate students do not know how to read a table. Data presented legibly is a big problem - not very good labeling of tables, for example. Students often do not take statistics till junior or senior year, even though it is required for their major in public affairs - there is a lot of fear and misunderstanding of statistics. I took stats in high school, college, and graduate school (sociology) though I am a qualitative researcher. I am developing a course on \"data and stories\" because I am convinced that statistical reasoning is underdeveloped in college work, especially policy work. I use Vox explainers and Pew Research presentations a lot in my policy courses. But if anyone can provide a good foundation in cross-tabs, (besides Earl Babbie\\'s text), I think that would be helpful to college students everywhere. This is a matter of good, informed citizens!',\n",
       "       'It would have been helpful to have the normal curve superimposed on the data.',\n",
       "       '-The premise of the study, that aggressiveness can be measured by the choice of a length of a noise blast, does not make sense to me.\\n-The undergrad population is not representative.\\n-Thus, apart from statistical issues, the results are doubtful.',\n",
       "       'The first figure is plotted incorrectly. Otherwise your questions have clear answers in statistics, so i think this is a dumb study.',\n",
       "       'Interesting study. The study has strong internal validity but would invoke caution for external validity because it\\'s not clear that the results (w N=800) are substantively meaningful to act upon in terms of determining policy. There\\'s a difference between statistically significant results and practically important results. Does a mean difference in noise blasts translate to bullying or other \"real world aggressive behaviors\" that folks (presumably) are trying to mitigate if not take to zero. Also, too much research is done w \"rich white kids from elite college institutions in the midwest, so the generalizability question is unresolved, but the study is an interesting start to what would need to be much more work done before pub (hence the 3 I gave it), you\\'ll need field studies etc. Also, this work reminds me of Brand Bushman\\'s stuff, which apparently has come into question in the context of replicability and the p hacking crisis in psychology.',\n",
       "       'I had never thought about translating means and SEâ€™s into probabilities ',\n",
       "       'I normally do not use statistics in my research. ',\n",
       "       'I learned that my statistical interpretation skills are fairly shaky.',\n",
       "       'This was a fun study, thank you! I also really appreciate the incentive.',\n",
       "       'I liked the warnings in yellow',\n",
       "       'The first scenario has an error which tainted my participation. The text mentions errors in the range of appx. 0.5 while the figure shows errors of appx. 0.05. Which is it? ',\n",
       "       \"Interesting study; if you had provided group standard deviations instead of standard errors I would have been able to provide better estimates.  I could have calculated the standard deviations from the standard errors and probably come up with much better estimates but instead I just looked at the distributions, the scales, and guessed.  The absence of a range on the scales made it more difficult to estimate the full distribution of scores.  Also, I've rarely been in a situation in which I've had to estimate the probability that a single score from one group would exceed the score of another group.  I'm very curious regarding what you're trying to show with this study.  By the way, the primary problem I had with your hypothetical abstract was that there were too criteria for aggressiveness but you measured only one of them, and there were alternative explanations for the finding.  The greater aggressiveness, if that's what it was, could have been a result of frustration with the game itself rather than the fact that observing violence made the respondents act more aggressively.\",\n",
       "       'None of the error bars could possibly represent 1 SD on the mean, given the distributions of points. ',\n",
       "       ' ',\n",
       "       'The design of the hypothetical study was so bad (e.g., using only university students in US who choose to participate in experiment) that it is not worth doing.  Further, the questions in your study were  not interesting enough for me to want to bother expending any effort.  It was clear that in all cases, any differences were not scientifically significant, even if they were statistically significant. ',\n",
       "       'The vertical axis of the plots were insufficiently explained to make credible judgements of the percentages requested. There was, for my field, an inconsistency between the abstract SD (assumed standard deviation) and the error bars in Figure 1. This was a major reason for rejecting the abstract. If you had allowed responses of insufficient information, I would have selected that option.',\n",
       "       \"I didn't use R when answering your questions, though it crossed my mind.\\n\",\n",
       "       \"I'm surprised there were no questions, or information, about effect sizes--especially for the first, overall question about acceptability of the abstract.\",\n",
       "       'Thanks, an interesting study.  ',\n",
       "       'In my field (CS/ML) just the presence of some kind of significance test is often questionable, so I wasn\\'t that familiar with standard deviation vs standard error -- almost no one uses SE. The first thing I noticed (other than the similarity of the \"noise blast\" to the Milgram experiments) was that the reported SD was way out of scale for the error bars in the plot. My first guess was that it was just wrong, but after reviewing the definition of standard error and trying out 0.5 / sqrt(798) I decided it looked correct. I then used python to figure out the mean and stddev for the rest of the questions and sampled 10000 variates from the two distributions, getting an empirical guess about the frequency of treatment being greater than control. I was a bit unsure about whether this is the expected procedure, but the instructions only said \"best guess\". If I hadn\\'t done calculations I would have had no clue for any of these except that it was > 50 and < 90.',\n",
       "       \"I participated in a psychology study as an undergraduate.  The stakes are essentially never high enough to cause people to answer the question honestly.  In the specific example, to do the study correctly would have been to show a person suffering as the punishment is applied.   If you would have done the study that way, the results would have been very different.  Of course, you can't do a study that way and hence my original point: psychology studies like this are worthless. \",\n",
       "       \"The question about whether an abstract would be accepted or not may be weird by discipline. In my discipline, editors tend to assess papers for their suitability for further review, but are substantially guided by reviewers. Desk rejects are uncommon, as compared to Science, Nature, PNAS, etc. As such, while I didn't find the video game study results especially compelling, I would probably have handed it to some reviewers I trusted with the stats to dig into it.\",\n",
       "       'I rejected the paper because effect size seems very low. sure they have significant results using large sample of 800 but the real effect seems trivial in size for substantive policy decisions ',\n",
       "       'It wasn\\'t clear whether you were asking about the probability that someone chosen at random from the treatment population works have a higher score than control, or someone from the sample. I interpreted \"group\" to mean in the sample, so tried to estimate from the plots, not taking into account certainty about the effect size in the population. ',\n",
       "       'None',\n",
       "       'As an academic, I am very interested in this topic. The researchers seems to test whether individuals can draw accurate probability estimates from graphs. The researchers give us a scenario and vary the sample size and the standard deviation and then ask us to provide a probability estimate. In my opinion, there might be serious methodological flaws in this experiment.\\n\\nFirst, I am not sure if question that the subjects must answer is statistically correct. The questions reads something like \"what is the probability of a subject randomly chosen from one group will have a higher score than another subject randomly chosen from another group\". Hence, the question is about the distribution of individual observations.\\n\\nThen there is an explanation below that says something like \"50% chance means that the two groups are not statistically significantly different from each other\". Does this refer to the distribution of individual observations or to the distribution of sample means? If\\n\\n\\nI do not think that these two statements are equivalent. One question is about two individual observations while the explanation is about parameters of two distributions. ',\n",
       "       'This seems really interesting, but as a qualitative social scientist, I am not at all qualified to interpret these statistics! ',\n",
       "       \"I'd say effects sizes are metrics of informed inference...not std errors!\",\n",
       "       'Major: I think it is open to some discussion about under what circumstances \"the probability that a random participant in group A has an outcome that is larger than a random participant in group B\" is the right metric.  I worry you\\'re about to write a paper that says people don\\'t know how to interpret stats because their intuition about that metric was wrong, but it doesn\\'t follow that people\\'s judgements about the significance of results is faulty, because depending on the context, that metric might or might not be the most important factor in deciding the significance of results.  It depends why we\\'re doing the study and what we\\'re trying to learn.  Even an effect that is only a fraction of the overall variation might still be important.  Minor: In one of your trials, the vertical lines were not evenly spaced, specifically, the gap from 0.8 to 1.0 was not drawn to scale, and the gaps between the other vertical lines was 0.3 rather than 0.2 (I think).',\n",
       "       \"That's a lot to ask of survey respondents with very little reward. PPE is cheap & our time is expensive.\",\n",
       "       'Sorry -- I thought that the first sample was the whole population and not one SD.',\n",
       "       'It would have been nice to have been able to express concerns about the population the sample was drawn from as was as the validity of the mechanism used to measure aggression.',\n",
       "       'In the first question I did not understand if I was reviewing the quality of the abstract or the quality of the research reported by the abstract.',\n",
       "       'I am not used to look at group differences in terms of individual probabilities -- too much can go wrong. Also, in most of the studies shown, the variations within the groups were way larger than the differences between the groups -- when reviewing such studies, I would ask authors to stay away from any individual interpretations (like the chance of an individual picked from each group).\\n\\nGroup difference do not easily allow individualized intepretations /expectations\\n\\nMy other question to the authors would be whether the differences go away as soon as individual proclivities for aggression or so are removed (controlled); without such controls, I would not easily accept the data, even with 800 subjects.',\n",
       "       'The first page question Q2 was very focused on sample size, but my \"reject\" in Q3 was based on a broader sense that the study was fishy. The jitter\\'ed samples were way to Gaussian to be real human behavioral data.',\n",
       "       'I really liked the time estimates and the PPE incentive. Very thoughtful. Looking forward to hearing about the study results.',\n",
       "       'This cracked me up, because I KNEW I never knew what those error bars were, because I KNEW different people had told me different things about them. But, I never bothered to try to figure out what they meant in the end... Shame on me as an academic. ;-)',\n",
       "       \"Regarding the article: Although it seems like the focus of this study is on statistics, I had concerns about the construct validity of both the manipulation and the outcome measure.\\n\\nIt would have been neat to know how well I guessed (though maybe you don't want your participants to give away answers?). \",\n",
       "       'The data shown in this abstract and with these exercises is not presented the way that it would be in my discipline.  I have never seen a paper that reported a standard error for a hypothesis test.',\n",
       "       'Instead of asking the participant to select a probability score, a task not suitable for non-statisticians, you could give different ranges and ask the participant to pick one. I can see that in some of the examples, the confidence intervals of means will be non-overlapping. However, mean +- 1 std.dev is not the most informative way to present the statistical data.',\n",
       "       'If I have more time, I would like to do some calculation before I give the estimations.',\n",
       "       'As a biologist, the wording of the abstract and the statistical tests used were outside of my expertise.',\n",
       "       'One thing I was thinking about the abstract was that even if the difference was *statistically* significant (i.e., there is a real difference in outcome), the size of the difference did not seem all that large.  That is, the effect seemed slight.  I would be wary of drawing much conclusion from that.  Given the public sensitivity to issues around violent video games, I can imagine ethical issues around reporting experiments that show statistically significant, but not *practically* significant, differences.',\n",
       "       'I did not initially understand that you were asking about the stability of standard errors.  The abstract did not report effect sizes and I was distracted by questions of base rates.   If I was actually reviewing this and not in a car, I would have double checked all my assumptions and readings of the data.',\n",
       "       'interface for 2nd part is clunky.  Need to submit twice for each question.  Also, need to reread the question looking for differences.',\n",
       "       \"Would reject first paper not because of statistics but because the overall numbers couldn't possibly be correct -- it had the log time in milliseconds was about 6.5, i.e. around 3 million milliseconds (log(3e6)=6.48), which is about an hour. So something is clearly wrong with the data reporting.\",\n",
       "       'Better estimates of the desired situations were possible if I could take time to look up tables (or compute basically).  I took your assessment of a total time of 15 minutes to imply you want shooting from the hip.  So done.',\n",
       "       'I gave my impressions without spending time looking anything up.  In writing or reviewing a paper, however, I consult Google for relevant statistical matters!',\n",
       "       'The question of \"accept/reject\" the article is an uninformative \"forced\" choice.  There is nothing close to an adequate basis for evaluating the study.  The analysis results and the sample size for groups are not irrelevant, but they are just the tip of the iceberg for what would really be considered.  There should have been either a qualifying phrase (assume the motivating theory,  other aspects of study design, and interpretation of results are all satisfactory) or provide an option for \"not enough information\".  Guessing at probabilities for two slightly non-overlapping normal curves is an interesting task. I assumed we were supposed to guess without trying to use normal theory calculations to improve on an off-the-cuff guess.  Hope I made a choice that was in line with what you wanted. ',\n",
       "       'I didn\\'t remember seeing any error bars at all on the first plot so completely made up a guess. You need to either show us the graph again or (if recall is part of the design) allow a \"don\\'t know\" option. If I were doing this formally I\\'d plug the numbers into a formula but just did a rough guess based on eyeballing the distributions and knowing it was a 0.3 sigma difference. ',\n",
       "       'The SEM does not provide the info needed to answer the questions posed. Graphing the data with +/- 1 SD yields a different story. Significance test may be interesting but they are also too often misleadfing',\n",
       "       'Interesting and challenging.',\n",
       "       'This survey looks like it is designed to shame academics, who can calculate correctly but who might guess incorrectly. Whatâ€™s the relevance of the number of refereeing instances? Presumably you want to conclude about refereeing accuracy, but when we referee, we donâ€™t GUESS.',\n",
       "       'As there was little incentive as an test subject (less incentive than being a referee) to get good estimates to your questions, I did not spend a lot of time \"guessing.\"  In reality (and as a referee) I would spend more time on getting the answers right as the consequences of making a wrong \"guess\" would be more severe. ',\n",
       "       'I assumed that standard error is the standard error of the mean. ',\n",
       "       \"I think the p-values were incorrect, assuming a normal distribution.  At an alpha of 5%, many of the pairs were not significantly different, so I don't understand the p-values.  Maybe that was what you were actually testing our knowledge of.\",\n",
       "       'The first study has ethics issues so I would not recommend publishing it.',\n",
       "       \"My response on whether I'd accept the hypothetical article for publication depends on the substantive size of the difference in means, not just statistical significance. The difference in exponentiated mean logged sound duration was something like 0.13 seconds. I don't know if that's real-world meaningful or not, statistical significance aside.\",\n",
       "       'Not being able to refer back to the original graph and abstract is an artificial constraint of this study that will likely bias the results. In evaluating the quality of a manuscript for publication, I read the full manuscript and refer back to tables, graphs, and text as needed to arrive at an informed decision about its quality. ',\n",
       "       'I  review scores of submitted journal articles for 8-10 journals in my professional field of practice but I am not a statistician and do not judge that part of the paper. Rather, I look for non-statistical methodological issues. For example, in your abstract, the opening sentences describes an interest in violence and non-violence of children and adults, but your subjects were undergraduates--which are neither children nor adults. To me, your study is flawed no matter what you found.',\n",
       "       \"Sometimes, I wasn't paying attention to which bar the treatment and control group were. I always picked a probability greater than 50% by the way it was worded, but you may have caught me there if you switched the labels.\",\n",
       "       'It was interesting (and difficult) to assign numerical probabilities in the last parts.  I would say that while I have enough statistics to understand (I hope!) when there is a problem, I certainly do not have enough statistics to be able to calculate (or even estimated) those probabilities.',\n",
       "       'Clever... I realize in retrospect I was initially not answering right question.  In years of teaching stat, I learned what you are learning now ... that even learned colleagues have a difficult time keeping straight the distinction between the distribution of a variable and the distribution of estimates of the mean of that variable.',\n",
       "       'Interesting study. Good luck ... ',\n",
       "       'My issue with the abstract article (and the main reason I would have rejected it) is that for this situation, the difference may have been statistically significant but the magnitude of the reported difference was tiny; given their large sample size, I\\'m not surprised that there was a low p-value. I would have much preferred to see an effect size or something like that. That said, the units they were working in were log-transformed; they probably would have been better off putting those back into \"real\" time intervals as part of their discussion and figure. In real space, the difference they were reporting was a bit more notable than it _appeared_ to be in log space; while I projected their point estimates back into real-space, I didn\\'t do the same for their standard deviation values, and I know from experience that intervals project in complicated ways out of log space so it\\'s possible that the error bars on their figure would have looked quite different in real space. I\\'m also not convinced that a t-test was the right statistical test; I imagine that the distributions of noise durations was pretty funky (with a floor and maybe also a ceiling effect) so I wonder if something non-parametric would have been a better choice. Oh, and I also would have liked to see some discussion (or at least a citation) validating their approach for measuring aggressiveness. \\n\\nAs to quantitatively interpreting the simulated figures- this is something that I know I\\'m terrible at doing \"by sight\" so I wouldn\\'t be surprised if my answers were wildly incorrect. As such, \"in the real world\" (i.e., when it matters), I often work out the appropriate proportions as part of making sense of a figure. Similarly, for interpreting standard error vs. standard deviation, that\\'s something I often find myself needing to look up to make sure I\\'m getting correct. I didn\\'t do that here, since I\\'m assuming that part of the goal is to find out how many of us actually _know_ this stuff properly! ðŸ¤£',\n",
       "       'Stats originated from counting population births and deaths. At that population size, of course, it makes a lot sense. But for small population problem, trying to quantify x% more likely or less likely predicted outcomes for doing certain things is probably not as meaningful, even though it can still be useful to some degree. ',\n",
       "       'It wasn\\'t clear to me whether your \"standard error\" referred to standard error of the mean, which I assumed it did since you were quoting means with \"standard errors\".  The wording seemed ambiguous to me.',\n",
       "       \"I thought the bars in Figure 1 didn't match the text.  I couldn't figure out why but it just didn't feel right.  That threw me off for the rest of the experiment.\\n\\nOne other not: I do theoretical work, not empirical work.\",\n",
       "       \"Please check to be sure data is valid from my survey -- I may have inadvertently corrupted it.\\n\\nI started the survey yesterday, but I was interrupted during the survey with urgent tasks (help with out-of-state parents' major injury) and could not resume until today.  My computer browser window stayed open and unchanged; my Windows computer went into 'sleep' mode until today.  Yesterday I had only entered radio-button choices on first page, but not hit the submit button.  I hit the 'back' button to start over, and was shown a totally different plot/figure -- yesterday I saw simple black-and-white line drawing with median and error-bars, today I was shown a color scatter-plot with error bars, yet the text appeared to be the same.  I completed the questions based on today's display.  \",\n",
       "       'It was difficult to know if the uncertainties (error bars) were standard deviations or standard deviations of the mean. I assumed the latter, and so I multiplied the error bars by a factor of root N (about 12 in the tests) to get the actual SDs. That approach greatly reduced the probability of differences for randomly chosen singe examples. I made no attempt to calculate the probabilities accurately but simply used my rough knowledge of Gaussian statistics.',\n",
       "       'I found it very frustrating as the plots were not at all designed to answer the questions asked. Would have liked a reminder on the difference between standard deviation (reported in the abstract) and standard error (reported on the plot). When you say \"guess\" and \"estimate\" it also wasn\\'t clear if you wanted us to compute anything or not (which goes back to the plot question...); it\\'s an easy question to answer if I were going to compute, but I\\'m not fluent with the associated probability tables so in various places I did estimate. Also, before I saw the \\'guess/estimate\\' part, for the first probability, I did run the numbers via a quick simulation as that\\'s much faster than the algebra. ',\n",
       "       'experiment seemed shallow and results were marginal.  not worth publishing.\\n\\nI am unclear about diff betw standard deviation and standard error (if any).  Questions about probability seemed difficult to work out technically.  I used rule of thumb that pr of being 1 sd from mean is about 2/3, 2 sd about 9/10, 3 sd about 99/100 -- or maybe should have been 97/100.  I have no intuition about sample size n = 60 versus n =400.',\n",
       "       \"You didn't ask, but the reason I was somewhat negative about the article is the question of whether the effect size itself is meaningful.  \",\n",
       "       'Your study seems to be testing familiarity with statistical summarization of data.  Such summaries are very important in some branches of science â€” and not at all important in others.   So I was surprised to see that you did not ask any background questions about field of expertise.',\n",
       "       \"I do a fair amount of stats, but it's all with categorical data and logistic regressions. So I'm actually rather out of practice with normal/continuous stuff. \",\n",
       "       \"I didn't notice the 1 sd (rather than 2 sd) confidence interval info right away. the sample size data seems just like a distraction since it should be part of the calculation of the sd. I was mentally trying to double the interval but not always very well, and I know I tended initially to dismiss all the results that didn't meet my best guess of being statistically significant at .05 level. But I wasn't willing to do the mental arithmetic for calculating the actual odds for a stupid test like this.    \"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_by_stage[df_by_stage.stage == 'FEEDBACK'].feedback.dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "618729f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_stage[df_by_stage.stage == 'FEEDBACK'].dropna(subset=['feedback'])[['assignmentId', 'workerId', 'condition', 'feedback']].to_csv(f\"../tidy-data/{experiment}-tidy-feedback.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c723fc2",
   "metadata": {},
   "source": [
    "### Timing data\n",
    "\n",
    "We recorded timestamps of the start and end in milliseconds since the Epoch. Mostly we are curious if they are completing the task too quickly (<3 minutes?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7bf835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_stage['elapsed'] = df_by_stage['currentTime'] - df_by_stage['startTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bda0ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_of_part1 = df_by_stage[df_by_stage.stage == 'PSUP_GAME_PREFACE'].currentTime - df_by_stage[df_by_stage.stage == 'PSUP_GAME_PREFACE'].startTime\n",
    "feedback_stage = df_by_stage[df_by_stage.stage == 'FEEDBACK'].currentTime - df_by_stage[df_by_stage.stage == 'FEEDBACK'].startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23e58c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 100.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.scatter(\n",
    "    range(len(feedback_stage)),\n",
    "    (feedback_stage / 1000 / 60).sort_values(),\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Participants ordered by time\")\n",
    "ax.set_xticks([])\n",
    "ax.set_ylabel(\"Experiment time in minutes\")\n",
    "ax.set_ylim([0, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f4a7a",
   "metadata": {},
   "source": [
    "# Cleanup before outputting\n",
    "\n",
    "We want the data to be tidy. Thus we will end up with four dataframes:\n",
    "\n",
    "* first is editorial\n",
    "* second is psup game \n",
    "* third is time stamps, with all stages (and maybe ts_trial_1, ts_trial_2, etc. for psup game?)\n",
    "* fourth is background survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec36f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_stage_per_assignment = df_by_stage.sort_values(by=['assignmentId', 'elapsed']).groupby('assignment_id').last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da8378e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New rule is that editorial data must have Part I of experiment completed\n",
    "# (ie, finished the PAPER_A_UNDERSTANDING stage)\n",
    "\n",
    "df_tidy_editorial = df_by_stage[df_by_stage.stage == 'PAPER_A_UNDERSTANDING'].drop(['currentTime', 'startTime', 'turkSubmitTo', 'guess', 'scenario', 'trial', 'background', 'feedback', 'mu1', 'mu2', 'variance1', 'variance2', 'n1', 'n2', 'probOfSuperiority'] + statsVars, axis=1)\n",
    "df_tidy_editorial.to_csv(f\"../tidy-data/{experiment}-tidy-editorial.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44510fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people who made it to various stages:\n",
      "INITIAL_PAGE_LOAD        566\n",
      "PAPER_A_PREFACE          519\n",
      "PAPER_A_REVIEW           443\n",
      "PAPER_A_PSUP             399\n",
      "PAPER_A_UNDERSTANDING    368\n",
      "PSUP_GAME                339\n",
      "BACKGROUND_SURVEY        295\n",
      "FEEDBACK                 289\n",
      "Name: stage, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# How much data will we lose if we require people finish Part I completely?\n",
    "\n",
    "print(\"Number of people who made it to various stages:\")\n",
    "print(df_by_stage.drop_duplicates(['assignmentId', 'stage']).stage.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ec4a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./results/{experiment}_finishers_by_stage.json\", \"w\") as out:\n",
    "    json.dump(\n",
    "        df_by_stage.drop_duplicates(['assignmentId', 'stage']).stage.value_counts().reset_index().rename(columns={'index': 'stage', 'stage': 'finishers'}).set_index(\"stage\").to_dict()['finishers'],\n",
    "        out\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "799450eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_vars = ['assignmentId', 'condition', 'experiment', 'hitId', 'id', 'study_id', 'workerId', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fe81f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing out psup game trials\n",
    "\n",
    "df_trials[common_vars + ['guess', 'trial', 'mu1', 'mu2', 'variance1', 'variance2', 'n1', 'n2', 'psup', 'signed_error', 'unsigned_error']].to_csv(f\"../tidy-data/{experiment}-tidy-psup-game.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a99f0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing out background data\n",
    "\n",
    "df_background_data = df_last_stage_per_assignment[common_vars + statsVars]\n",
    "df_background_data.to_csv(f\"../tidy-data/{experiment}-tidy-background.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a90d795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing out timing data\n",
    "\n",
    "df_by_stage['stage_trial'] = df_by_stage.stage + '-' + df_by_stage.trial.fillna('1')\n",
    "df_by_stage[common_vars + ['stage', 'trial', 'stage_trial', 'elapsed']].to_csv(f\"../tidy-data/{experiment}-tidy-elapsed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
